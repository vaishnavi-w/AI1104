{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q1B_AI20BTECH11025.ipynb","provenance":[{"file_id":"1tsPbHSAr9HMM_W_3iC8FFKKnPPmkVYrx","timestamp":1627058199454}],"collapsed_sections":[],"authorship_tag":"ABX9TyNXdqp5loQVxCnwj6bwfm4v"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"coSsG10LORGZ"},"source":["import numpy as np\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iP74vpcXUa1Y"},"source":["# Function to generate training/testing samples\n","def samples(N):\n","    # Generate N - equi spaced floats in the interval [0, 2*pi]\n","    x = np.linspace(0, 2*np.pi, N)\n","    # Generate noice\n","    mean = 0 \n","    std = 0.05\n","    # Generate some numbers from the sine function \n","    y = np.sin(x)\n","    # Add noise\n","    y += np.random.normal(mean,std,N) \n","    return x,y\n","\n","# Function to generate matrix X\n","def matrix_X(N,m,x):\n","    # Generate an array of ones of size (N, m+1)\n","    X = np.ones([N,m+1])\n","    # Replacing ones in the matrix in the second column onwards with x, x^2, x^3 ...., x^m \n","    for i in range(N):\n","        for j in range(1,m+1):\n","          X[i][j] = x[i]**j\n","    return X\n","\n","# Calculating beta = (X^T.X)^(-1).X_T.y\n","def beta(X,Y):\n","    # X transpose \n","    X_transpose = X.T\n","    # Matrix multiplication of X transpose and X\n","    Z = np.dot(X_transpose, X)\n","    # Calculating of pseudo inverse matrix\n","    Pseudo_inverse = np.linalg.inv(Z)\n","    # Multiplying pseudo inverse, X transpose and Y matrices \n","    B = Pseudo_inverse @ X_transpose @ Y \n","    return B \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fRXH4-bWR-Sr"},"source":["# Value of m \n","m=2\n","# Number of training samples N\n","N=10\n","# Number of testing samples T\n","T=5\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs poorly on the test and the training data. It is underfitting, does not fit the data well enough.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzpvv4RoZFKx"},"source":["# Value of m \n","m=2\n","# Number of training samples N\n","N=100\n","# Number of testing samples T\n","T=10\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs poorly on the test and the training data. It is underfitting, does not fit the data well enough.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BoS1BJGoZb89"},"source":["# Value of m \n","m=2\n","# Number of training samples N\n","N=1000\n","# Number of testing samples T\n","T=20\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs poorly on the test and the training data. It is underfitting, does not fit the data well enough.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"plUIr6c4ZfGQ"},"source":["# Value of m \n","m=3\n","# Number of training samples N\n","N=10\n","# Number of testing samples T\n","T=5\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGX8C6o6ZgVo"},"source":["# Value of m \n","m=3\n","# Number of training samples N\n","N=100\n","# Number of testing samples T\n","T=10\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shFiFWclCYX0"},"source":["# Value of m \n","m=3\n","# Number of training samples N\n","N=1000\n","# Number of testing samples T\n","T=20\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E5mkkMXQCcs5"},"source":["# Value of m \n","m=4\n","# Number of training samples N\n","N=10\n","# Number of testing samples T\n","T=4\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yKhROz_Cfvp"},"source":["# Value of m \n","m=4\n","# Number of training samples N\n","N=100\n","# Number of testing samples T\n","T=10\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xeKeRG6LCh2o"},"source":["# Value of m \n","m=4\n","# Number of training samples N\n","N=1000\n","# Number of testing samples T\n","T=20\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iO1Rw9uxCk4i"},"source":["# Value of m \n","m=5\n","# Number of training samples N\n","N=10\n","# Number of testing samples T\n","T=4\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSLTfj5pCnCK"},"source":["# Value of m \n","m=5\n","# Number of training samples N\n","N=100\n","# Number of testing samples T\n","T=10\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnulqFGDCoga"},"source":["# Value of m \n","m=5\n","# Number of training samples N\n","N=1000\n","# Number of testing samples T\n","T=20\n","\n","# Using the function samples() training samples x and respective ground truth labels y are generated\n","x,y = samples(N)\n","\n","# Using function matrix_X() X matrix is generated\n","X = matrix_X(N,m,x)\n","# Using function beta() vector B of model parameters is generated\n","B = beta(X,y)\n","# Predicted labels \n","y_hat = np.dot(X, B)\n","\n","print('Model parameters : ', B)\n","\n","# TESTING SAMPLES\n","# Using the function samples() testing samples test_x and respective ground truth labels test_y are generated\n","test_x,test_y = samples(T)\n","# Matix X is generated for the testing samples\n","test_X = matrix_X(T,m,test_x)\n","# Matrix multiplication of X and B gives the predicted labels \n","test_y_hat = np.dot(test_X, B)\n","\n","# MSE is calcuated by taking the mean of squares of difference between ground truth and predicted labels for the testing data\n","error = np.square(test_y - test_y_hat).mean()\n","error_train = np.square(y - y_hat).mean()\n","print('MSE between the predicted and ground truth labels in testing data:',error_train)\n","print('MSE between the predicted and ground truth labels in testing data :', error)\n","\n","# Displaying the data\n","plt.plot(x,y,'o',label='Training data')\n","plt.plot(test_x,test_y_hat,'rx',label='Testing data')\n","plt.plot(x,y_hat)\n","plt.axis('equal')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.show()\n","\n","print('Observations : The ML model performs well on the test and the training data. It is appropriate. The low MSE error confirms the same')"],"execution_count":null,"outputs":[]}]}